{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46bca38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer, DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import faiss\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0afaa8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotlines = [\n",
    "    {\"name\": \"COP2COP\", \"description\": \"Support for police officers dealing with trauma.\"},\n",
    "    {\"name\": \"Suicide Prevention Hotline\", \"description\": \"Support for individuals with suicidal thoughts.\"},\n",
    "    {\"name\": \"NJ Addiction Hotline\", \"description\": \"Support for individuals struggling with substance use.\"},\n",
    "]\n",
    "\n",
    "# Create documents to index\n",
    "documents = [f\"{entry['name']}: {entry['description']}\" for entry in hotlines]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ba89622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n",
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# Initialize FAISS and create an index\n",
    "tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "model = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "\n",
    "# Tokenize and encode documents\n",
    "inputs = tokenizer(documents, return_tensors='pt', padding=True, truncation=True)\n",
    "embeddings = model(**inputs).pooler_output.detach().numpy()\n",
    "\n",
    "# Use FAISS to index the embeddings\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])  # Index for fast search\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82a88f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"James is a police officer experiencing work-related trauma.\"\n",
    "\n",
    "# Encode the query using DPRQuestionEncoder\n",
    "question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
    "question_model = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
    "\n",
    "# Tokenize and encode the query\n",
    "query_inputs = question_tokenizer(query, return_tensors='pt', padding=True, truncation=True)\n",
    "query_embedding = question_model(**query_inputs).pooler_output.detach().numpy()\n",
    "\n",
    "# Search FAISS index to find the most relevant hotlines\n",
    "D, I = index.search(query_embedding, k=3)  # Retrieve top 3 hotlines\n",
    "retrieved_hotlines = [documents[i] for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ca2a690",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_text = \"\\n\".join(retrieved_hotlines)\n",
    "prompt = f\"The user is experiencing: {query}\\nHere are some suggested hotlines:\\n{retrieved_text}\\nPlease explain why these hotlines are appropriate for the user's situation.\"\n",
    "\n",
    "openai.api_key = 'sk-vcluRbh8_Y_LTW4rYNJZ_OIe0AG5iZOKBaj99sEmn0T3BlbkFJmyNWqmOrh3BkZ-YrMHcyuzUgCU26oHqPNhGTPo3LAA'\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant recommending hotline services.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "  ],\n",
    "  temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4bd590c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d2b0680c5cf452889a641ba5ddacb82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80791830fe584c11bf557d4ba9a648c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9376ddd32184d9e8f0243090bf5d581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e0d76e97514be9846bf15f4b1640e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/492 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43adf8fea9a04acf84508c9dd4558a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaomo/opt/anaconda3/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356c401ea1a344dfb9a2bf76ccaaff3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3087563ebf7e4deda878017468beb566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5656cbf1594943b8a400f3528d0913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda9179111c04324a5072fc735c7a7f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/493 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72c8aedf2a50482cbf919eb0baef579a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4's recommended hotlines and reasoning:\n",
      "1. COP2COP: This hotline is specifically designed to provide support for police officers dealing with work-related trauma, stress, and other mental health issues. Given that James is a police officer who is experiencing work-related trauma, it's highly suitable. The operators are often former law enforcement officers themselves, and they are familiar with the unique pressures and struggles that come with the job.\n",
      "\n",
      "2. Suicide Prevention Hotline: This hotline provides immediate assistance to individuals in suicidal crisis by connecting them to the nearest available crisis center. People experiencing trauma, like James, may have suicidal thoughts and this service could provide immediate help and support.\n",
      "\n",
      "3. NJ Addiction Hotline: It is not uncommon for individuals undergoing trauma to turn to substance use as a coping mechanism. If James has developed or is at risk of developing a substance use disorder due to his work-related trauma, this hotline can provide him with the resources he needs to get help.\n",
      "\n",
      "Retrieved Hotlines:\n",
      "COP2COP: Support for police officers dealing with trauma.\n",
      "Suicide Prevention Hotline: Support for individuals with suicidal thoughts.\n",
      "NJ Addiction Hotline: Support for individuals struggling with substance use.\n"
     ]
    }
   ],
   "source": [
    "print(\"GPT-4's recommended hotlines and reasoning:\")\n",
    "print(response['choices'][0]['message']['content'])\n",
    "\n",
    "print(\"\\nRetrieved Hotlines:\")\n",
    "for hotline in retrieved_hotlines:\n",
    "    print(hotline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e6a868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
